# Projet Pipeline ELT

## ğŸŒ Contexte
Ce projet a Ã©tÃ© rÃ©alisÃ© dans le cadre du module "Data Engineering" Ã  HETIC (promo DIA2).
Il consiste Ã  crÃ©er un pipeline ELT complet de lâ€™ingestion Ã  la modÃ©lisation, en utilisant un dataset libre sur les voitures.

---

## ğŸ“š Objectifs du projet

- Ingestion de donnÃ©es brutes Ã  partir dâ€™un fichier CSV
- Stockage dans PostgreSQL via Docker
- Transformation et modÃ©lisation des donnÃ©es en base
- Orchestration automatique du pipeline
- Documentation claire et livrables prÃªts pour soutenance

---

## âš™ï¸ Technologies utilisÃ©es

- **Python** : ingestion, orchestration
- **PostgreSQL** : base de donnÃ©es relationnelle
- **Docker** : environnement de base de donnÃ©es isolÃ©
- **psycopg2-binary / pandas / sqlalchemy** : connexion et manipulation de donnÃ©es
- **SQL** : crÃ©ation des tables et transformations
- **dotenv / Makefile / logging / time** : gestion dâ€™environnement, automatisation, journalisation

---

## ğŸ¤– Installation du projet

### 1. Cloner le repo
```bash
git clone https://github.com/votre-utilisateur/Projet-Pipeline-ELT.git
cd Projet-Pipeline-ELT
```

### 2. Initialiser lâ€™environnement
```bash
cp .env.example .env
python3 -m venv venv
source venv/bin/activate
pip install -r requirements.txt
```

### 3. Lancer PostgreSQL avec Docker
```bash
docker compose up -d
```

---

## ğŸ“ Utilisation du pipeline

### 1. Ingestion simple (brute)
```bash
python scripts/extract_load.py
```

### 2. Orchestration complÃ¨te (ingestion + transformations)
```bash
python scripts/orchestrator.py
```

### 3. Ou via le Makefile :
```bash
make run       # Lance docker
make etl       # Lance le pipeline complet
make stop      # Stoppe les conteneurs
make reset     # Stoppe tout + supprime les volumes
```

Un rapport automatique est gÃ©nÃ©rÃ© dans `logs/report.txt` Ã  chaque exÃ©cution.

---

## ğŸ“Š Structure du projet

```
Projet-Pipeline-ELT/
â”œâ”€â”€ data/raw/                # DonnÃ©es sources (non versionnÃ©es)
â”œâ”€â”€ docs/                    # SchÃ©mas, prÃ©sentation, PPT
â”œâ”€â”€ scripts/                 # Scripts Python : ingestion + orchestration
â”œâ”€â”€ sql/                    # CrÃ©ation des tables et transformations
â”œâ”€â”€ logs/                   # Logs d'exÃ©cution et rapports
â”œâ”€â”€ .env.example            # Variables dâ€™environnement (exemple)
â”œâ”€â”€ docker-compose.yml      # Conteneur PostgreSQL
â”œâ”€â”€ Makefile                # Automatisation
â”œâ”€â”€ requirements.txt        # Packages Python
â””â”€â”€ README.md               # Ce fichier
```

---

## ğŸ§° Equipe

- **GrÃ©gory** : Orchestration & Ingestion
- **Othmann** : ModÃ©lisation & SQL
- **Lucien** : Documentation & PrÃ©sentation

---

## âœ… Livrables attendus

- [x] Code source (Python, SQL) via GitHub
- [x] Fichier `.env.example` et `README.md`
- [x] SchÃ©ma du pipeline (`docs/schema_pipeline.png`)
- [x] SchÃ©ma BDD (`docs/schema_bdd.png`)
- [x] `presentation.pptx` pour soutenance (max 10 min)

---

## ğŸ”’ Notes

- Ne pas versionner `.env` ni `venv/`
- Docker doit Ãªtre configurÃ© avec WSL2 sur chaque poste
- PostgreSQL tourne sur `localhost:5432` par dÃ©faut
- VÃ©rifier les ports et configurations dans `docker-compose.yml`
- Les logs sont gÃ©nÃ©rÃ©s dans `logs/` pour chaque exÃ©cution

